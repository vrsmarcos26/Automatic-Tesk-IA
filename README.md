<div align="center">
  <h1>
    Agentes de IA com Autogen e Function Calling
  </h1>
</div>

<p align="center">
  <img alt="Linguagem Principal" src="https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white">
  <img alt="Licen√ßa" src="https://img.shields.io/github/license/vrsmarcos26/Automatic-Tesk-IA?style=for-the-badge&color=blue">
</p>

<p align="center">
  Um laborat√≥rio pr√°tico que explora a cria√ß√£o de agentes de IA com o framework Microsoft Autogen, utilizando Function Calling para estender suas capacidades com ferramentas Python customizadas.
</p>

<p align="center">
  <a href="#-objetivos-de-aprendizagem">Objetivos</a> ‚Ä¢
  <a href="#-tecnologias-utilizadas">Tecnologias</a> ‚Ä¢
  <a href="#-como-rodar-o-projeto">Como Rodar</a> ‚Ä¢
  <a href="#-demonstra√ß√£o">Demonstra√ß√£o</a> ‚Ä¢
  <a href="#-licen√ßa">Licen√ßa</a>
</p>

---

### üéØ Objetivos de Aprendizagem

-   Entender o paradigma de **sistemas multi-agente** com Microsoft Autogen.
-   Implementar **"Function Calling" (Uso de Ferramentas)** para dar aos agentes capacidades al√©m da linguagem.
-   Integrar um LLM de alta velocidade via **Groq API** (com o modelo Llama 3).
-   Diferenciar os pap√©is do `AssistantAgent` (o pensador) e do `UserProxyAgent` (o executor).

---

### üõ†Ô∏è Tecnologias Utilizadas

Este projeto combina um framework de agentes de IA com uma API de infer√™ncia de LLM de alta performance.

<p align="center">
  <a href="#"><img src="https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white" alt="Python"></a>
  <a href="#"><img src="https://img.shields.io/badge/Jupyter-F37626?style=for-the-badge&logo=jupyter&logoColor=white" alt="Jupyter"></a>
  <a href="#"><img src="https://img.shields.io/badge/AutoGen-A724B5?style=for-the-badge&logo=microsoft&logoColor=white" alt="AutoGen"></a>
  <a href="#"><img src="https://img.shields.io/badge/Groq-00C592?style=for-the-badge&logo=groq&logoColor=white" alt="Groq"></a>
</p>

---

### ‚öôÔ∏è Como Rodar o Projeto

O laborat√≥rio foi projetado para ser executado no **Google Colab**.

#### 1. Pr√©-requisitos
-   Uma **API Key da Groq**. Voc√™ pode obter uma gratuitamente no (https://console.groq.com/login).

#### 2. Configure a API Key
-   Abra o notebook `03_function_calling_agent.ipynb` no Google Colab.
-   No menu esquerdo, v√° em **Secrets (üîë)** e crie um novo secret chamado `groq`.
-   Cole sua API Key da Groq no campo de valor. [cite: 243, 261] [cite_start]A utiliza√ß√£o do `userdata.get('groq')` √© uma forma mais segura de gerenciar chaves.

#### 3. Instale as Depend√™ncias
Execute a primeira c√©lula do notebook para instalar as bibliotecas:
```bash
pip install autogen groq
```

#### 4. Execute o Laborat√≥rio
Execute as c√©lulas em sequ√™ncia para ver os agentes em a√ß√£o. Sinta-se √† vontade para modificar o `system_message`, as fun√ß√µes e as mensagens do usu√°rio para testar outros cen√°rios.

---

### üé¨ Demonstra√ß√£o

O laborat√≥rio consiste em adaptar um agente. Inicialmente, ele √© um `currency_bot` para convers√£o de moedas. Depois, seu `system_message` e suas ferramentas s√£o alterados para que ele se torne um assistente de automa√ß√£o residencial.

**Comando do Usu√°rio:** `E ai, truta! Est√° calor, hein? [cite_start]Estou na sala`

**Resultado:** O agente entende a inten√ß√£o, chama a ferramenta correta (`turn_on_airconditioner`) com os par√¢metros certos (`ambiente="Sala de estar"`, `estado=True`) e confirma a execu√ß√£o da tarefa.

<summary><strong>üí° An√°lise T√©cnica do Fluxo (Write-up)</strong></summary>
<br>

O conceito de **Function Calling** no Autogen segue um fluxo de trabalho claro:

1.  **Defini√ß√£o da Ferramenta**: Uma fun√ß√£o Python comum √© criada (ex: `turn_on_airconditioner`).

2.  **Registro da Ferramenta**: A fun√ß√£o √© registrada usando dois decoradores:
    -   `@agent.register_for_llm()`: Informa ao `AssistantAgent` que a ferramenta existe, o que ela faz (atrav√©s da `description`) e quais par√¢metros ela aceita.
    -   `@user_proxy.register_for_execution()`: Autoriza o `UserProxyAgent` a executar essa fun√ß√£o quando o assistente solicitar.

3.  **Fluxo de Execu√ß√£o**:
    -   O usu√°rio envia uma mensagem atrav√©s de `user_proxy.initiate_chat()`. 
    -   O `AssistantAgent` (com o LLM) analisa a mensagem e a descri√ß√£o das ferramentas. Ele conclui que deve chamar uma fun√ß√£o.
    -   Ele n√£o executa a fun√ß√£o, mas envia uma "sugest√£o de chamada de ferramenta" ao proxy, com os argumentos preenchidos (ex: `{"ambiente": "Sala de estar", "estado":true}`).
    -   O `UserProxyAgent` recebe a sugest√£o, executa a fun√ß√£o Python localmente (`EXECUTING FUNCTION...`) e retorna o resultado (ex: "Ar condicionado do Sala de estar foi ligado").
    -   O `AssistantAgent` recebe este resultado e formula uma resposta final em linguagem natural para o usu√°rio (ex: "Ahhh, que um ar fresco come√ßou a circular!").


---

### üìù Licen√ßa

Este projeto est√° sob a licen√ßa MIT.

<hr>

<p align="center">
  Desenvolvido por <b>Marcos Vin√≠cius Rocha Silva</b>
</p>
